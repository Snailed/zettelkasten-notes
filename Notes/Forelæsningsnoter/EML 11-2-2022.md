Graphical models
	Directed, undirected
	Can be used to express complex computations required for inference and can visualize the structure of a probabilistic model.
	Examples: Mixtures models, factor analysis, ..., Neural Networks (especially hybrid models), Generative neural network models
	Consists of...
		Node: A random variable
		Edges: A probabilistic relationship
	Directed graphical models or Bayesian Networks can be used to express causal relationships between variables
	Undirected graphical models or Markov random fields can be used to express soft constraints
	Example:
		$$p(a,b,c)=p(c|a,c)p(a,b)=p(c|a,b)p(b|a)p(a)$$
		For $k$ variables, if it is fully expanded we get a full network. It is more interesting to see where there is not a link than where there is a link
	We choose our factorizations such that the graphs are DAG (directed acyclic graphs)

Polynomial Regression Example
	Random variables are weights and observed data
	Deterministic variables are x with a noise $\sigma^2$ and $\alpha$ representing the precision of the Gaussian prior over $w$ and $p(w)$.
	This is related to graphical models since the regression is a joint probability over t and w, where we factor to $p(w)\Pi p(t_n|w)$
	Observed vs latent/hidden variables

Generative vs discriminative.
	Discriminative seperates, where generative models the distribution

Generative models:
	If you want to draw a sample from the joint distribution, you can use ancestral sampling:
		Order the nodes in some way, draw a sample from the conditional distribution for each node along with its parents (read more on slides)
		
1-of-K representation: a discrete variable that can take K different states can be shown as a vector with a manhattan length of 1

When working with discrete variables, we want them to be independent, otherwise each random variable will have many parents (see slides)

Dirichlet prior? Sharing or Tying parameters?

Conditional independence is very useful for reducing the amount of computations
Conditional independence can be read directly from a graph without having to perform any analytical manipulations using _d-seperation_

D-separation:
To ascertain A (cond. independent sign) B|C
	Consider all blocked paths from any node A to any node B
	....Ã˜V DETTE!

Markov blanket
Markov random fields (undirected graphical models)
Cliques
Hammersly and Clifford theorem

Moralization
D-maps og I-maps
