[[Nocedal, Wright - Numerical Optimization]] page 626
If for a function $f$ is [[Frechet differentiable]], then we can denote $g$ as
$$\nabla f(x) = (\frac{\delta f}{\delta x_0}, \frac{\delta f}{\delta x_1}, \dots, \frac{\delta f}{\delta x_{n-1}})^T$$
It is thus a vector of partial derivatives.

A gradient with respect to only a subset of variables are denoted $\nabla_{x_i, \dots x_j}f(x)$.

The gradient-of-a-gradient is the [[Hessian matrix]]